# lexer.c 疑似コード

## 関数: restore_spaces
- **引数**:
  - `str`: 文字列
- **処理**:
  1. 文字列中の特殊文字（ASCII 1-6）を元の空白文字に戻す。

## 関数: add_split_tokens
- **引数**:
  - `tokens`: トークンリストへのポインタ
  - `value`: 分割対象の文字列
- **処理**:
  1. `value` を空白文字で分割する。
  2. 分割された各単語について、`restore_spaces` で空白を復元し、新しい `TOKEN_WORD` トークンを作成してリストに追加する。

## 関数: process_word_token
- **引数**:
  - `input`: 入力文字列
  - `i`: 現在のインデックスへのポインタ
  - `tokens`: トークンリストへのポインタ
  - `data`: シェルの主要データ構造体
- **処理**:
  1. `build_combined_word` を呼び出し、単語とクォートタイプを取得する。
  2. 取得した単語が存在する場合:
     - 単語が空で、かつクォートされていた場合 (`quote_type != 0`):
       - 空文字のトークンを追加する。
     - 単語が空でない場合:
       - `add_split_tokens` を呼び出し、空白で分割してトークンを追加する。
     - 単語を解放する。

## 関数: process_token
- **引数**:
  - `input`: 入力文字列
  - `i`: 現在のインデックスへのポインタ
  - `tokens`: トークンリストへのポインタ
  - `data`: シェルの主要データ構造体
- **処理**:
  1. `|` の場合: パイプトークンを追加し、インデックスを進める。
  2. `<` または `>` の場合: `handle_redirect` を呼び出す。
  3. その他の場合: `process_word_token` を呼び出す。

## 関数: lexer
- **引数**:
  - `input`: 入力文字列
  - `data`: シェルの主要データ構造体
- **処理**:
  1. トークンリスト `tokens` を `NULL` に初期化する。
  2. 入力文字列の終わりまでループする:
     - 空白をスキップする。
     - 文字があれば `process_token` を呼び出し、トークンを生成・追加する。
  3. トークンリストを返す。
